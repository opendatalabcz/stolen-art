{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import pathlib\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " def downscale_images(images, scale=30):\n",
    "    \"\"\"\n",
    "    Downscales images in an array.\n",
    "    Args:\n",
    "        images: array of images to be downscaled \n",
    "        scale: \n",
    "\n",
    "    Returns: array of downscaled down images\n",
    "\n",
    "    \"\"\"\n",
    "    resized = []\n",
    "    \n",
    "    for img in images:\n",
    "        \n",
    "        width = int(img.shape[1] * scale / 100)\n",
    "        height = int(img.shape[0] * scale / 100)\n",
    "        dim = (width, height)\n",
    "\n",
    "        resized.append(cv2.resize(img, dim, interpolation = cv2.INTER_AREA))\n",
    "    \n",
    "    return resized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess(path):\n",
    "    \n",
    "    \n",
    "    # directory with the images\n",
    "    data_dir = pathlib.Path(path)\n",
    "    \n",
    "    \n",
    "    # how many images are in the directory\n",
    "    image_count = len(list(data_dir.glob('*')))\n",
    "    print(f\"Number of images found in {path}: {image_count}\")\n",
    "\n",
    "\n",
    "    paintings_path = list(data_dir.glob('*'))\n",
    "    paintings_path = [str(path) for path in paintings_path]\n",
    "    \n",
    "    # sort by img number\n",
    "    paintings_path = sorted(paintings_path, key=lambda path: int(path.split('_')[-1].split('.')[0]))\n",
    "    \n",
    "    \n",
    "    # loading images, in BGR\n",
    "    paintings = [cv2.imread(painting_path) for painting_path in paintings_path]\n",
    "    paintings = downscale_images(paintings)\n",
    "    \n",
    "    \n",
    "    # converting to gray\n",
    "    paintings_gray = [cv2.cvtColor(painting, cv2.COLOR_BGR2GRAY) for painting in paintings]\n",
    "    \n",
    "    # converting to RGB for later visualisation\n",
    "    paintings_rgb = [cv2.cvtColor(painting, cv2.COLOR_BGR2RGB) for painting in paintings]\n",
    "    \n",
    "    painting_tuple = (paintings_gray, paintings_rgb)\n",
    "    \n",
    "    return painting_tuple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading stolen paintings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images found in ./Tate-500-wop-opac/: 477\n"
     ]
    }
   ],
   "source": [
    "stolen_art_dir_path = \"./Tate-500-wop-opac/\"\n",
    "stolen_paintings = load_and_preprocess(stolen_art_dir_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading found paintings\n",
    "Paintings which I want to test against the stolen images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images found in ./Tate-500-wop-opac_aug/: 477\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'aug'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-245c9929db17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfound_paintings_dir_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./Tate-500-wop-opac_aug/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfound_paintings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_paintings_dir_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-4059452065aa>\u001b[0m in \u001b[0;36mload_and_preprocess\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# sort by img number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mpaintings_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaintings_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-4059452065aa>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# sort by img number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mpaintings_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaintings_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'aug'"
     ]
    }
   ],
   "source": [
    "found_paintings_dir_path = \"./Tate-500-wop-opac_aug/\" \n",
    "found_paintings = load_and_preprocess(found_paintings_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_compared(img1, img2):\n",
    "    # Display traning image and testing image\n",
    "    fx, plots = plt.subplots(1, 2, figsize=(20,10))\n",
    "\n",
    "    plots[0].set_title(\"Stolen Image\")\n",
    "    plots[0].imshow(img1)\n",
    "\n",
    "    plots[1].set_title(\"Comparing to\")\n",
    "    plots[1].imshow(img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling functions for visualisation\n",
    "\n",
    "Functions mainly for downscaling the paintings/keypoints before visualisation. Greatly reduces the size of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_deepcopy (f):\n",
    "    return [cv2.KeyPoint(x = k.pt[0], y = k.pt[1], \n",
    "            _size = k.size, _angle = k.angle, \n",
    "            _response = k.response, _octave = k.octave, \n",
    "            _class_id = k.class_id) for k in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_keypoints(keypoints, scale):\n",
    "    \n",
    "    for keypoint in keypoints:\n",
    "        new_x = math.trunc(keypoint.pt[0]*(scale/100) )\n",
    "        new_y = math.trunc(keypoint.pt[1]*(scale/100) )\n",
    "        keypoint_scaled = (new_x, new_y) \n",
    "        keypoint.pt = keypoint_scaled\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_matches_scaled(found_painting, found_painting_keypoints,\n",
    "                        stolen_painting, stolen_painting_keypoints,\n",
    "                        matches, matchesMask, draw_params, scale = 20):\n",
    "    \n",
    "    # scale the paintings\n",
    "    found_painting = downscale_images([found_painting], scale)[0]\n",
    "    stolen_painting = downscale_images([stolen_painting], scale)[0]\n",
    "    \n",
    "    found_painting_keypoints_scaled = features_deepcopy(found_painting_keypoints)\n",
    "    scale_keypoints(found_painting_keypoints_scaled, scale)\n",
    "    \n",
    "    stolen_painting_keypoints_scaled = features_deepcopy(stolen_painting_keypoints)\n",
    "    scale_keypoints(stolen_painting_keypoints_scaled, scale)\n",
    "\n",
    "    result = cv2.drawMatchesKnn(found_painting, found_painting_keypoints_scaled,\n",
    "                                stolen_painting, stolen_painting_keypoints_scaled,\n",
    "                                matches, None, **draw_params)\n",
    "    \n",
    "    return result\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an ORB object\n",
    "orb = cv2.ORB_create(nfeatures=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_keypoints(image, keypoints, scale = 100):\n",
    "    \n",
    "    # SCALE HAS TO BE 100, TODO\n",
    "    \n",
    "    keypoints_without_size = np.copy(image)\n",
    "    keypoints_with_size = np.copy(image)\n",
    "\n",
    "    keypoints_without_size = downscale_images([keypoints_without_size], scale)[0]\n",
    "    keypoints_with_size = downscale_images([keypoints_with_size], scale)[0]\n",
    "    \n",
    "    keypoints_scaled = features_deepcopy(keypoints)\n",
    "    scale_keypoints(keypoints_scaled, scale)\n",
    "    \n",
    "    cv2.drawKeypoints(image, keypoints_scaled, keypoints_without_size, color = (0, 255, 0))\n",
    "\n",
    "    cv2.drawKeypoints(image, keypoints_scaled, keypoints_with_size, flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "    \n",
    "    # Display image with and without keypoints size\n",
    "    fx, plots = plt.subplots(1, 2, figsize=(20,10))\n",
    "\n",
    "    plots[0].set_title(\"Train keypoints With Size\")\n",
    "    plots[0].imshow(keypoints_with_size)\n",
    "\n",
    "    plots[1].set_title(\"Train keypoints Without Size\")\n",
    "    plots[1].imshow(keypoints_without_size)\n",
    "    \n",
    "    print(\"Number of Keypoints Detected In The Stolen Image: \", len(keypoints))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the algorithm\n",
    "\n",
    "Find keypoints on every image in the database. Display the keypoints with their size (left) and without (right)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_results = []\n",
    "\n",
    "for index, _ in enumerate(stolen_paintings[0]):\n",
    "\n",
    "    orb_res = orb.detectAndCompute(stolen_paintings[0][index], None)\n",
    "    orb_results.append(orb_res)\n",
    "\n",
    "    sp_keypoints, sp_descriptors = orb_res\n",
    "    \n",
    "    #visualize_keypoints(stolen_paintings[1][index], sp_keypoints, scale=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching for a painting in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def search_for_painting(painting_index, draw_match = True):\n",
    "    \n",
    "    found_painting = found_paintings[0][painting_index]\n",
    "    found_painting_rgb = found_paintings[1][painting_index]\n",
    "    found_painting_keypoints, found_painting_descriptor = orb.detectAndCompute(found_painting, None)\n",
    "\n",
    "    best_match_index, matches, mask = get_best_match(found_painting_descriptor)\n",
    "    \n",
    "    if best_match_index < 0:\n",
    "        print(\"Sorry, no match found for painting: \")\n",
    "        plt.imshow(found_paintings[1][painting_index])\n",
    "        return\n",
    "    \n",
    "    if draw_match:\n",
    "        draw_matches(best_match_index, found_painting_rgb, found_painting_keypoints, matches, mask)\n",
    "    \n",
    "    return best_match_index\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLANN Based Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. parametr FlannBasedMatcheru\n",
    "FLANN_INDEX_LSH = 6\n",
    "index_params= dict(algorithm = FLANN_INDEX_LSH,\n",
    "                   table_number = 6, # 12\n",
    "                   key_size = 12,     # 20\n",
    "                   multi_probe_level = 1) #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. parametr FlannBasedMatcheru\n",
    "search_params = dict(checks=50)   # or pass empty dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_match(found_painting_descriptor, k = 2, min_matches = 10):\n",
    "\n",
    "    matches_count = {}\n",
    "    \n",
    "    matches = {}\n",
    "    matches[-1] = None\n",
    "    \n",
    "    matches_masks = {}\n",
    "    matches_masks[-1] = None\n",
    "    \n",
    "    \n",
    "    for index, stolen_res in enumerate(orb_results):\n",
    "        stolen_keypoints, stolen_descriptor = stolen_res\n",
    "\n",
    "        # Cross check parametr\n",
    "        flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "        # Perform the matching between the ORB descriptors of the training image and the test image\n",
    "        matches[index] = flann.knnMatch(stolen_descriptor, found_painting_descriptor, k)\n",
    "        # deskriptor = \"fingerprint\" keypointu, vektor 0 a 1, napr. BRIEF rozmaze misto a z toho spocita vektor\n",
    "        # ORB muze pouzivat rBRIEF, tzn. pocita i s rotaci obrazu\n",
    "\n",
    "        ok_matches_num = 0\n",
    "\n",
    "        # Need to draw only good matches, so create a mask\n",
    "        matches_masks[index] = [[0,0] for i in range(len(matches[index]))]\n",
    "        # ratio test as per Lowe's paper\n",
    "        for i, candidates in enumerate(matches[index]):\n",
    "            if (len(candidates)<2):\n",
    "                continue # nedostatek bodu pro porovnani\n",
    "            m, n = candidates    \n",
    "            if m.distance < 0.7*n.distance:\n",
    "                matches_masks[index][i]=[1,0]\n",
    "                ok_matches_num = ok_matches_num + 1 \n",
    "        \n",
    "        matches_count[index] = ok_matches_num\n",
    "        \n",
    "    \n",
    "        \n",
    "        # print(\"Pocet prijatelnych matchu: \", ok_matches_num)\n",
    "        \n",
    "    best_match_index = max(matches_count, key=matches_count.get)\n",
    "    #print(type(best_match_index))\n",
    "    best_match_index = best_match_index if matches_count[best_match_index] >= min_matches else -1\n",
    "        \n",
    "    return best_match_index, matches[best_match_index], matches_masks[best_match_index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_matches(stolen_index, found_painting, found_painting_keypoints, matches, matchesMask):\n",
    "    \n",
    "    draw_params = dict(matchColor = (0,255,0),\n",
    "                       singlePointColor = (255,0,0),\n",
    "                       matchesMask = matchesMask,\n",
    "                       flags = cv2.DrawMatchesFlags_DEFAULT)\n",
    "\n",
    "    \n",
    "    \n",
    "    result = draw_matches_scaled(found_painting, found_painting_keypoints,\n",
    "                                 stolen_paintings[1][stolen_index], orb_results[stolen_index][0],\n",
    "                                 matches, matchesMask, draw_params, 100)\n",
    "    \n",
    "    # Display the best matching points\n",
    "    plt.rcParams['figure.figsize'] = [28.0, 14.0]\n",
    "    plt.title('Painting found! Best match: ')\n",
    "    plt.imshow(result)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the algorithm on all the paintings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_searched = len(found_paintings[0])\n",
    "not_found = 0\n",
    "found_ok = 0\n",
    "found_wrong = 0\n",
    "\n",
    "for index in range(0, total_searched):\n",
    "    best_match_index = search_for_painting(index, draw_match = True)\n",
    "    \n",
    "    print(index)\n",
    "    print(best_match_index)\n",
    "    \n",
    "    if index is None:\n",
    "        not_found = not_found + 1\n",
    "    elif index == best_match_index:\n",
    "        found_ok = found_ok + 1\n",
    "    elif index != best_match_index:\n",
    "        found_wrong = found_wrong + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = found_ok / (not_found + found_wrong)\n",
    "print(f\"Accuracy: {accuracy*100} %\")\n",
    "total_searched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nápad na vylepšení: porovnávat směry vektoru, vyhodit outsidery\n",
    "# + zkoumat relativni polohu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching nalezeného obrazu s obrazy v DB  pomocí Brute Force Matcher\n",
    "\n",
    "\n",
    "BFMatcher - Obsahuje parametr crossCheck, údajně dobrá alternativa k ratio testu, ale mně nefunguje dobře. Znamená to, že namatchuje pouze body, které jsou si nejpodobnější navzájem, tzn. pro žádný z dvojice neexistuje v druhém obraze lepší match. Pokud ho dám na False, matcher namatchuje všechny body a výsledek je uplně k ničemu. Pokud na true, matcher namatchuje cca polovinu bodů, ale u všech obrazů a je proto taky k ničemu.\n",
    "\n",
    "Mnohem lépe se mi osvědčila kombinace knnMatch a ratio testu.\n",
    "\n",
    "**crossCheck se samozřejmě nedá kombinovat s knnMatch ! !**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "zdroj: https://docs.opencv.org/master/dc/dc3/tutorial_py_matcher.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbfm = 2\n",
    "\n",
    "for index, stolen_res in enumerate(orb_results):\n",
    "    stolen_keypoints, stolen_descriptor = stolen_res\n",
    "\n",
    "    # Cross check parametr\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING2, crossCheck = False)\n",
    "\n",
    "        \n",
    "    \n",
    "    # Perform the matching between the ORB descriptors of the training image and the test image\n",
    "    matches = bf.knnMatch(stolen_descriptor, suspect_descriptor, kbfm)\n",
    "    # deskriptor = \"fingerprint\" keypointu, vektor 0 a 1, napr. BRIEF rozmaze misto a z toho spocita vektor\n",
    "    # ORB muze pouzivat rBRIEF, tzn. pocita i s rotaci obrazu\n",
    "    \n",
    "   \n",
    "    # Apply ratio test\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.75*n.distance:\n",
    "            good.append([m])\n",
    "\n",
    "    result = cv2.drawMatchesKnn(stolen_paintings[1][index], stolen_keypoints, suspected_painting_rgb, suspect_keypoints, good, None, flags = 2)\n",
    "    \n",
    "    # Display the best matching points\n",
    "    plt.rcParams['figure.figsize'] = [28.0, 14.0]\n",
    "    plt.title('Best Matching Points')\n",
    "    plt.imshow(result)\n",
    "    plt.show()\n",
    "\n",
    "    # Print total number of matching points between the training and query images\n",
    "    print(\"Celkový počet dobrých match (po ratio testu): \", len(good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SAR",
   "language": "python",
   "name": "sar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
