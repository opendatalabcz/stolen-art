{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Disclaimer\n",
    "This notebook contains experiments not included in the thesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import pathlib\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def downscale_images(images, scale=30):\n",
    "    \"\"\"\n",
    "    Downscales images in an array.\n",
    "    Args:\n",
    "        images: array of images to be downscaled \n",
    "        scale: \n",
    "\n",
    "    Returns: array of downscaled down images\n",
    "\n",
    "    \"\"\"\n",
    "    resized = []\n",
    "    \n",
    "    for img in images:\n",
    "        \n",
    "        width = int(img.shape[1] * scale / 100)\n",
    "        height = int(img.shape[0] * scale / 100)\n",
    "        dim = (width, height)\n",
    "\n",
    "        resized.append(cv2.resize(img, dim, interpolation = cv2.INTER_AREA))\n",
    "    \n",
    "    return resized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess(path):\n",
    "    \n",
    "    \n",
    "    # directory with the images\n",
    "    data_dir = pathlib.Path(path)\n",
    "    \n",
    "    \n",
    "    # how many images are in the directory\n",
    "    image_count = len(list(data_dir.glob('*')))\n",
    "    print(f\"Number of images found in {path}: {image_count}\")\n",
    "\n",
    "\n",
    "    paintings_path = list(data_dir.glob('*'))\n",
    "    paintings_path = [str(path) for path in paintings_path]\n",
    "    \n",
    "    # sort by img number\n",
    "    paintings_path = sorted(paintings_path, key=lambda path: int(path.split('_')[-1].split('.')[0]))\n",
    "    \n",
    "    \n",
    "    # loading images, in BGR\n",
    "    paintings = [cv2.imread(painting_path) for painting_path in paintings_path]\n",
    "    paintings = downscale_images(paintings)\n",
    "    \n",
    "    \n",
    "    # converting to gray\n",
    "    paintings_gray = [cv2.cvtColor(painting, cv2.COLOR_BGR2GRAY) for painting in paintings]\n",
    "    \n",
    "    # converting to RGB for later visualisation\n",
    "    paintings_rgb = [cv2.cvtColor(painting, cv2.COLOR_BGR2RGB) for painting in paintings]\n",
    "    \n",
    "    painting_tuple = (paintings_gray, paintings_rgb)\n",
    "    \n",
    "    return painting_tuple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading stolen paintings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stolen_art_dir_path = \"../datasets/Tate-500-oil-canvas/\"\n",
    "stolen_paintings = load_and_preprocess(stolen_art_dir_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading found paintings\n",
    "Paintings which I want to test against the stolen images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_paintings_dir_path = \"../datasets/Tate-500-oil-canvas/\" \n",
    "found_paintings = load_and_preprocess(found_paintings_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_compared(img1, img2):\n",
    "    # Display traning image and testing image\n",
    "    fx, plots = plt.subplots(1, 2, figsize=(20,10))\n",
    "\n",
    "    plots[0].set_title(\"Stolen Image\")\n",
    "    plots[0].imshow(img1)\n",
    "\n",
    "    plots[1].set_title(\"Comparing to\")\n",
    "    plots[1].imshow(img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling functions for visualisation\n",
    "\n",
    "Functions mainly for downscaling the paintings/keypoints before visualisation. Greatly reduces the size of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_deepcopy (f):\n",
    "    return [cv2.KeyPoint(x = k.pt[0], y = k.pt[1], \n",
    "            _size = k.size, _angle = k.angle, \n",
    "            _response = k.response, _octave = k.octave, \n",
    "            _class_id = k.class_id) for k in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_keypoints(keypoints, scale):\n",
    "    \n",
    "    for keypoint in keypoints:\n",
    "        new_x = math.trunc(keypoint.pt[0]*(scale/100) )\n",
    "        new_y = math.trunc(keypoint.pt[1]*(scale/100) )\n",
    "        keypoint_scaled = (new_x, new_y) \n",
    "        keypoint.pt = keypoint_scaled\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_matches_scaled(found_painting, found_painting_keypoints,\n",
    "                        stolen_painting, stolen_painting_keypoints,\n",
    "                        matches, matchesMask, draw_params, scale = 20):\n",
    "    \n",
    "    # scale the paintings\n",
    "    found_painting = downscale_images([found_painting], scale)[0]\n",
    "    stolen_painting = downscale_images([stolen_painting], scale)[0]\n",
    "    \n",
    "    found_painting_keypoints_scaled = features_deepcopy(found_painting_keypoints)\n",
    "    scale_keypoints(found_painting_keypoints_scaled, scale)\n",
    "    \n",
    "    stolen_painting_keypoints_scaled = features_deepcopy(stolen_painting_keypoints)\n",
    "    scale_keypoints(stolen_painting_keypoints_scaled, scale)\n",
    "\n",
    "    result = cv2.drawMatchesKnn(found_painting, found_painting_keypoints_scaled,\n",
    "                                stolen_painting, stolen_painting_keypoints_scaled,\n",
    "                                matches, None, **draw_params)\n",
    "    \n",
    "    return result\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an ORB object\n",
    "orb = cv2.ORB_create(nfeatures=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_keypoints(image, keypoints, scale = 100):\n",
    "        \n",
    "    keypoints_without_size = np.copy(image)\n",
    "    keypoints_with_size = np.copy(image)\n",
    "\n",
    "    keypoints_without_size = downscale_images([keypoints_without_size], scale)[0]\n",
    "    keypoints_with_size = downscale_images([keypoints_with_size], scale)[0]\n",
    "    \n",
    "    keypoints_scaled = features_deepcopy(keypoints)\n",
    "    scale_keypoints(keypoints_scaled, scale)\n",
    "    \n",
    "    cv2.drawKeypoints(image, keypoints_scaled, keypoints_without_size, color = (0, 255, 0))\n",
    "\n",
    "    cv2.drawKeypoints(image, keypoints_scaled, keypoints_with_size, flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "    \n",
    "    # Display image with and without keypoints size\n",
    "    fx, plots = plt.subplots(1, 2, figsize=(20,10))\n",
    "\n",
    "    plots[0].set_title(\"Train keypoints With Size\")\n",
    "    plots[0].imshow(keypoints_with_size)\n",
    "\n",
    "    plots[1].set_title(\"Train keypoints Without Size\")\n",
    "    plots[1].imshow(keypoints_without_size)\n",
    "    \n",
    "    print(\"Number of Keypoints Detected In The Stolen Image: \", len(keypoints))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the algorithm\n",
    "\n",
    "Find keypoints on every image in the database. Display the keypoints with their size (left) and without (right)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_results = []\n",
    "\n",
    "for index, _ in enumerate(stolen_paintings[0]):\n",
    "\n",
    "    orb_res = orb.detectAndCompute(stolen_paintings[0][index], None)\n",
    "    orb_results.append(orb_res)\n",
    "\n",
    "    sp_keypoints, sp_descriptors = orb_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching for a painting in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def search_for_painting(painting_index, draw_match = True):\n",
    "    \n",
    "    found_painting = found_paintings[0][painting_index]\n",
    "    found_painting_rgb = found_paintings[1][painting_index]\n",
    "    found_painting_keypoints, found_painting_descriptor = orb.detectAndCompute(found_painting, None)\n",
    "\n",
    "    # search for nearest ORB painting\n",
    "    best_match_index, matches, mask = get_best_match(found_painting_descriptor)\n",
    "    \n",
    "    \n",
    "    # check histogram correlation\n",
    "    hist_corr = 0\n",
    "    if best_match_index is not None:\n",
    "        hist_corr = compare_hists(found_paintings_hists[painting_index], stolen_paintings_hists[best_match_index])\n",
    "    \n",
    "    \n",
    "    # indexes of paintings in DB which will not be matched with current painting again\n",
    "    excluded_indexes = []\n",
    "    tried = 0\n",
    "    while hist_corr <= 0.02 and tried < 10 and False:\n",
    "        previous = best_match_index\n",
    "        previous_hc = hist_corr\n",
    "        \n",
    "        if best_match_index == painting_index:\n",
    "            display_compared(found_paintings[1][best_match_index], stolen_paintings[1][painting_index])\n",
    "        \n",
    "        excluded_indexes.append(best_match_index)\n",
    "        best_match_index, matches, mask = get_best_match(found_painting_descriptor, exclude=excluded_indexes)\n",
    "        \n",
    "        if best_match_index is not None:\n",
    "            hist_corr = compare_hists(found_paintings_hists[index], stolen_paintings_hists[best_match_index])\n",
    "        \n",
    "        print(f\"Previous match for {painting_index}: {previous}, hist_corr: {hist_corr}.\\\n",
    "        New match: {best_match_index} with hist_corr: {hist_corr}\")\n",
    "        \n",
    "        tried = tried + 1\n",
    "    \n",
    "    \n",
    "    if best_match_index < 0 and draw_match:\n",
    "        print(f\"Sorry, no match found for painting: {painting_index}\")\n",
    "        plt.imshow(found_paintings[1][painting_index])\n",
    "        return\n",
    "    \n",
    "    if draw_match:\n",
    "        draw_matches(best_match_index, found_painting_rgb, found_painting_keypoints, matches, mask)\n",
    "    \n",
    "    return best_match_index\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Techniques to improve accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance as dist\n",
    "\n",
    "def calculate_histograms(images, bin_size = 32):\n",
    "    \n",
    "    hists = [cv2.calcHist([image], [0, 1, 2], None, [bin_size, bin_size, bin_size], [0, 256, 0, 256, 0, 256])\n",
    "             for image in images]\n",
    "    \n",
    "    hists = [cv2.normalize(hist, hist).flatten() for hist in hists]\n",
    "    \n",
    "    return hists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_paintings_hists = calculate_histograms(found_paintings[1])\n",
    "stolen_paintings_hists = calculate_histograms(stolen_paintings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_hists(hist1, hist2):\n",
    "    \n",
    "    corr = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)\n",
    "    \n",
    "    return corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLANN Based Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLANN_INDEX_LSH = 6\n",
    "index_params= dict(algorithm = FLANN_INDEX_LSH,\n",
    "                   table_number = 6, # 12\n",
    "                   key_size = 12,     # 20\n",
    "                   multi_probe_level = 1) #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = dict(checks=50)   # or pass empty dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_match(found_painting_descriptor,exclude=[], k = 2, min_matches = 10):\n",
    "\n",
    "    matches_count = {}\n",
    "    matches_count[-1] = 0\n",
    "    \n",
    "    matches = {}\n",
    "    matches[-1] = None\n",
    "    \n",
    "    matches_masks = {}\n",
    "    matches_masks[-1] = None\n",
    "    \n",
    "    \n",
    "    for index, stolen_res in enumerate(orb_results):\n",
    "        stolen_keypoints, stolen_descriptor = stolen_res\n",
    "\n",
    "        if index in exclude:\n",
    "            continue\n",
    "        \n",
    "        # if there is not enough features, continue\n",
    "        if found_painting_descriptor is None or len(found_painting_descriptor) <= k or stolen_descriptor is None or len(stolen_descriptor) <= k:\n",
    "            best_match_index = -1\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        # Cross check parameter\n",
    "        flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "        # Perform the matching between the ORB descriptors of the training image and the test image\n",
    "        matches[index] = flann.knnMatch(stolen_descriptor, found_painting_descriptor, k)\n",
    "\n",
    "        ok_matches_num = 0\n",
    "\n",
    "        # Need to draw only good matches, so create a mask\n",
    "        matches_masks[index] = [[0,0] for i in range(len(matches[index]))]\n",
    "\n",
    "        # ratio test as per Lowe's paper\n",
    "        for i, candidates in enumerate(matches[index]):\n",
    "            if (len(candidates)<2):\n",
    "                continue # not enough features for comparison\n",
    "                \n",
    "            m, n = candidates    \n",
    "            if m.distance < 0.7*n.distance:\n",
    "                matches_masks[index][i]=[1,0]\n",
    "                ok_matches_num = ok_matches_num + 1 \n",
    "        \n",
    "        matches_count[index] = ok_matches_num\n",
    "            \n",
    "        \n",
    "        # print(\"Amount of good matches: \", ok_matches_num)\n",
    "        \n",
    "    best_match_index = max(matches_count, key=matches_count.get)\n",
    "    best_match_index = best_match_index if matches_count[best_match_index] >= min_matches else -1\n",
    "        \n",
    "    return best_match_index, matches[best_match_index], matches_masks[best_match_index] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_matches(stolen_index, found_painting, found_painting_keypoints, matches, matchesMask):\n",
    "    \n",
    "    draw_params = dict(matchColor = (0,255,0),\n",
    "                       singlePointColor = (255,0,0),\n",
    "                       matchesMask = matchesMask,\n",
    "                       flags = cv2.DrawMatchesFlags_DEFAULT)\n",
    "\n",
    "    \n",
    "    \n",
    "    result = draw_matches_scaled(found_painting, found_painting_keypoints,\n",
    "                                 stolen_paintings[1][stolen_index], orb_results[stolen_index][0],\n",
    "                                 matches, matchesMask, draw_params, 100)\n",
    "    \n",
    "    # Display the best matching points\n",
    "    plt.rcParams['figure.figsize'] = [28.0, 14.0]\n",
    "    plt.title('Painting found! Best match: ')\n",
    "    plt.imshow(result)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the algorithm on all the paintings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_searched = len(found_paintings[0])\n",
    "not_found = {}\n",
    "found_ok = {}\n",
    "found_wrong = {}\n",
    "\n",
    "histograms_good_match = []\n",
    "histograms_bad_match = []\n",
    "\n",
    "for index in range(0, len(found_paintings[1])):\n",
    "    \n",
    "    \n",
    "    best_match_index = search_for_painting(index, draw_match = False)    \n",
    "    \n",
    "    if index % 10:\n",
    "        print(f\"Best match for {index} is {best_match_index}\")\n",
    "\n",
    "    hist_corr = compare_hists(found_paintings_hists[index], stolen_paintings_hists[best_match_index])\n",
    "    if index == best_match_index:\n",
    "        histograms_good_match.append(hist_corr)\n",
    "    else:\n",
    "        histograms_bad_match.append(hist_corr)\n",
    "    \n",
    "    \n",
    "    if index is None or index == -1:\n",
    "        not_found[index] = best_match_index\n",
    "    elif index == best_match_index:\n",
    "        found_ok[index] = best_match_index\n",
    "    elif index != best_match_index:\n",
    "        found_wrong[index] = best_match_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(found_ok))\n",
    "print(len(not_found))\n",
    "print(len(found_wrong))\n",
    "accuracy = len(found_ok) / (len(found_ok) + len(not_found) + len(found_wrong))\n",
    "print(f\"Accuracy: {accuracy*100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(orb_results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms vs ORB analysis\n",
    "How correlated were the histograms depending on whether ORB matched them correctly or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#print(hist_good_match)\n",
    "hists_g = pd.DataFrame(histograms_good_match).rename(columns={0:\"Good\"})\n",
    "print(hists_g.describe())\n",
    "\n",
    "hists_b = pd.DataFrame(histograms_bad_match).rename(columns={0:\"Bad\"})\n",
    "print(hists_b.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image_tuples(index_dict, limit=20):\n",
    "    \n",
    "    cnt = 0\n",
    "    for index_searched, index_found in index_dict.items():\n",
    "        \n",
    "        fx, plots = plt.subplots(1, 2, figsize=(20,10))\n",
    "    \n",
    "        plots[0].set_title(\"Searched image:\")\n",
    "        plots[0].imshow(found_paintings[1][index_searched])\n",
    "\n",
    "        plots[1].set_title(\"Wrongly matched with:\")\n",
    "        plots[1].imshow(stolen_paintings[1][index_found])\n",
    "        cnt = cnt + 1\n",
    "        if cnt > limit:\n",
    "            return\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_image_tuples(found_wrong)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SAR",
   "language": "python",
   "name": "sar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
